{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a83d9a1a-55e1-4cc6-bc2a-9d115a1bb88d",
   "metadata": {},
   "source": [
    "# Data Setup\n",
    "\n",
    "This chapter mostly focuses on data setup in order to prepare the `connect` function in `beaccess.py`.\n",
    "This chapter differs from the others in that all of the code is set up and should work out of the box.\n",
    "You do not need to input any information (unless, if you are an advanced user, have specific changes you want to make).\n",
    "\n",
    "The first section prepares the data by creating a dictionary of lists.\n",
    "Following that, there is a section that explains how to set up your backend,\n",
    "and it contains a sub-section for a few different backends.\n",
    "\n",
    "Backend sections will store the data created in the first section\n",
    "into reachable locations, and then the final code block will modify `beaccess.py`\n",
    "with access to that data (by writing re-writing the module programmatically)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364faa29-da15-4d63-a2b1-62ad02d7428c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 0.1.0 Raw Data\n",
    "\n",
    "We will be using mock farm data to work through the following chapters.\n",
    "\n",
    "Our goal is to create [tabular data](https://en.wikipedia.org/wiki/Table_(database))\n",
    "that we can store in a reachable location.\n",
    "We can then use Ibis to take this data and perform several actions on it,\n",
    "like [filtering](https://en.wikipedia.org/wiki/Filter_(higher-order_function)),\n",
    "[aggregating](https://en.wikipedia.org/wiki/Aggregate_data),\n",
    "or combining (through [joins](https://en.wikipedia.org/wiki/Join_(SQL))).\n",
    "\n",
    "You don't need to know what these things are yet, as they will be explained in the next few chapters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af0e4d4-107c-443b-8f32-fea4af004921",
   "metadata": {},
   "source": [
    "### 0.1.1 Summary\n",
    "\n",
    "We will be using mock farm data to walk through our exercises and apply a practical application of Ibis.\n",
    "\n",
    "In the following chapters, we will imagine that we are looking through and analyzing a set of farms.\n",
    "\n",
    "Each farm has a record of harvest information--what crops were harvested,\n",
    "when those crops were harvested,\n",
    "who harvested them,\n",
    "and where they were harvested.\n",
    "\n",
    "Farms are split up by [tracts](https://en.wikipedia.org/wiki/Land_lot) (which are large plots of land),\n",
    "and tracts are split up by [fields](https://en.wikipedia.org/wiki/Field_(agriculture)) (large plots of land that\n",
    "we grow crops on).\n",
    "\n",
    "These will be explained further in detail as we go through the tutorial,\n",
    "so if something seems unclear or overwhelming, do not worry and just move on.\n",
    "The gist of this is we are creating a set of tables that help us imagine what farm records might look like."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbee5673-fc0b-425c-b23a-5854106cb017",
   "metadata": {},
   "source": [
    "## 0.1.2 Data Creation\n",
    "\n",
    "To prepare our tables, we will create a dictionary of lists.\n",
    "\n",
    "Each list will be the data for our table, and the dictionary key for that list will be the table name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f64da5f6-7a5f-4a27-991f-af35c83ed47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list()\n",
    "data = dict()\n",
    "\n",
    "# Start a dictionary to store arguments for beaccess.py generation\n",
    "beaccess_kwargs = dict()\n",
    "\n",
    "# Farmer data - these are people that work on our farms\n",
    "data['farmers'] = [\n",
    "    ['farmer_id', 'farmer_name']\n",
    "    ,[1, 'Alice']\n",
    "    ,[2, 'Bob']\n",
    "    ,[3, 'Mallory']\n",
    "    ,[4, 'Pat']\n",
    "    ,[5, 'Carol']\n",
    "    ,[6, 'Carlos']\n",
    "    ,[7, 'Charlie']\n",
    "    ,[8, 'Yves']\n",
    "]\n",
    "\n",
    "# Farm data - this is general information about the farm\n",
    "# name, location on our grid, address\n",
    "data['farms'] = [\n",
    "    [\n",
    "        'farm_id','farm_name'\n",
    "        ,'farm_address'\n",
    "        ,'farm_origin_x','farm_origin_y'\n",
    "    ],[\n",
    "        1, 'North Farm'\n",
    "        ,\"{'street_address': '100 North St', 'city': 'City00', 'state': 'State00', 'postal_code': '00000'}\"\n",
    "        ,1, 7\n",
    "    ],[\n",
    "        2, 'East Farm'\n",
    "        ,\"{'street_address': '100 East St', 'city': 'City00', 'state': 'State00', 'postal_code': '00000'}\"\n",
    "        ,4, 2\n",
    "    ],[\n",
    "        3, 'South Farm'\n",
    "        ,\"{'street_address': '200 South St', 'city': 'City01', 'state': 'State01', 'postal_code': '00001'}\"\n",
    "        ,-2, -6\n",
    "    ],[\n",
    "        4, 'West Farm'\n",
    "        ,\"{'street_address': '300 West St', 'city': 'City02', 'state': 'State02', 'postal_code': '00002'}\"\n",
    "        ,-5, 2\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Farms are partitioned by tracts\n",
    "# Tracts are plots of land on a farm that are broken up into fields\n",
    "data['tracts'] = [\n",
    "    ['tract_id', 'tract_farm_id']\n",
    "    ,[1, 1]\n",
    "    ,[2, 1]\n",
    "    ,[3, 2]\n",
    "    ,[4, 2]\n",
    "    ,[5, 3]\n",
    "    ,[6, 4]\n",
    "]\n",
    "\n",
    "# Tracts are partitioned by fields\n",
    "# Fields are plots of land on a farm tract that are designated for growing crops\n",
    "data['fields'] = [\n",
    "    ['field_id', 'field_tract_id', 'field_vertices']\n",
    "    ,[1, 1, [[0, 2], [1, 3], [2, 0], [3, 1]]]\n",
    "    ,[2, 1, [[2, 2], [3, 2], [3, 1]]]\n",
    "    ,[3, 2, [[0, 1], [-1, 0], [-2, 0], [-2, 1]]]\n",
    "    ,[4, 3, [[0, 1], [1, 1], [1, 2], [0, 2]]]\n",
    "    ,[5, 3, [[1, 0], [2, 0], [2, 3], [1, 3]]]\n",
    "    ,[6, 3, [[2, 0], [3, 0], [3, 2], [2, 2]]]\n",
    "    ,[7, 4, [[-1, -1], [0, -1], [0, -2]]]\n",
    "    ,[8, 4, [[1, 0], [1, -2], [0, -2], [0, -1]]]\n",
    "    ,[9, 5, [[1, 0], [2, 0], [1, -1], [1, -2], [-1, -2], [-1, -1], [-2, 0], [-1, 0], [0, -1]]]\n",
    "    ,[10, 6, [[-1, 2], [0, 2], [0, 0], [-1, 0]]]\n",
    "    ,[11, 6, [[0, 2], [1, 2], [1, 1], [0, 1]]]\n",
    "]\n",
    "\n",
    "# Date information for harvest dates\n",
    "data['dates'] = [\n",
    "    ['date_id', 'date_year', 'date_month', 'date_day']\n",
    "    ,[1, 2021, 8, 4]\n",
    "    ,[2, 2021, 8, 26]\n",
    "    ,[3, 2022, 8, 3]\n",
    "    ,[4, 2022, 8, 25]\n",
    "]\n",
    "\n",
    "# Crop information for crops harvested/planted\n",
    "data['crops'] = [\n",
    "    ['crop_id', 'crop_name', 'crop_unit']\n",
    "    ,[1, 'soybean', 'bu']\n",
    "    ,[2, 'potato', 'kg']\n",
    "]\n",
    "\n",
    "# Farmer groups - which farmers from our farmers table have worked together\n",
    "data['farmer_groups'] = [\n",
    "    ['farmer_group_id', 'farmer_group_members']\n",
    "    ,[1, [1, 3, 4]]\n",
    "    ,[2, [2, 4, 5]]\n",
    "    ,[3, [6, 8]]\n",
    "    ,[4, [1, 6]]\n",
    "]\n",
    "\n",
    "# Harvest detail - which field harvested how many of what crop on what date and which groups performed the harvest?\n",
    "data['harvest'] = [\n",
    "    ['harvest_id', 'harvest_field_id', 'harvest_farmer_group_id', 'harvest_crop_id', 'harvest_date_id', 'harvest_value']\n",
    "    ,[1, 1, 1, 1, 1, 65.80]\n",
    "    ,[2, 2, 1, 2, 2, 5750.00]\n",
    "    ,[3, 3, 1, 1, 1, 59.85]\n",
    "    ,[4, 4, 2, 2, 2, 10100.00]\n",
    "    ,[5, 5, 2, 1, 1, 90.30]\n",
    "    ,[6, 6, 2, 2, 2, 21000.00]\n",
    "    ,[7, 7, 2, 2, 2, 5150.00]\n",
    "    ,[8, 8, 2, 1, 1, 53.55]\n",
    "    ,[9, 9, 3, 1, 1, 147.00]\n",
    "    ,[10, 10, 4, 1, 1, 70.70]\n",
    "    ,[11, 11, 4, 2, 2, 9600.00]\n",
    "    ,[12, 1, 1, 2, 4, 22800.00]\n",
    "    ,[13, 2, 1, 1, 3, 19.25]\n",
    "    ,[14, 3, 1, 2, 4, 13050.00]\n",
    "    ,[15, 4, 2, 1, 3, 31.15]\n",
    "    ,[16, 5, 2, 2, 4, 33000.00]\n",
    "    ,[17, 6, 2, 1, 3, 64.40]\n",
    "    ,[18, 7, 2, 1, 3, 16.45]\n",
    "    ,[19, 8, 2, 2, 4, 15000.00]\n",
    "    ,[20, 9, 3, 2, 4, 38400.00]\n",
    "    ,[21, 10, 4, 2, 4, 19800.00]\n",
    "    ,[22, 11, 4, 1, 3, 34.30]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a64fdd5-b104-450a-81e9-79d259e48c60",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 0.1.3 Storing Data\n",
    "\n",
    "To use the data you've created, you need to store it where your backend can reach it.\n",
    "Here are various methods of getting your data where it needs to be in order to connect to it.\n",
    "\n",
    "Expand the section below for the backend you are using and follow its directions to populate\n",
    "the data you will use to complete the next lessons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3124473-faca-4150-bddc-4fa1ea4923de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### \"DuckDB\" / \"pandas\"\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️:</b> Alters Current Directory\n",
    "\n",
    "    This creates a new directory in the current directory and writes several parquet files into it.\n",
    "    If the paths exist, then those paths will be overwritten.\n",
    "</div>\n",
    "\n",
    "The code below will create a directory, `farm_data/`, and write several parquet files containing mock farm data.\n",
    "DuckDB can connect to these files directly after they are written.\n",
    "\n",
    "Pandas requires a dictionary of pandas.DataFrames, so we will read these parquets and then create that dictionary\n",
    "to connect to the pandas backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99e9999c-46bf-4780-9659-c1918280ea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "FARM_DATA_DIR = 'farm_data'\n",
    "\n",
    "\n",
    "def write_data(data, fname, dname=FARM_DATA_DIR, fmt='parquet'):\n",
    "    if not os.path.exists(dname):\n",
    "        os.mkdir(dname)\n",
    "    path = '.'.join([os.path.join(dname, fname), fmt])\n",
    "\n",
    "    try:\n",
    "        os.remove(path)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if fmt in ['csv', 'txt']:\n",
    "        with open(path, 'w') as f:\n",
    "            for row in data:\n",
    "                line = '|'.join(str(e) for e in row)\n",
    "                f.write(line)\n",
    "                f.write('\\n')\n",
    "    elif fmt in ['parquet']:\n",
    "        df = pd.DataFrame(data[1:], columns=data[0])\n",
    "        df.to_parquet(path, index=False)\n",
    "    return path\n",
    "\n",
    "\n",
    "for key in data:\n",
    "    files.append(write_data(data[key], key))\n",
    "\n",
    "beaccess_kwargs['duckdb'] = f\"\"\"\n",
    "def duckdb_conn():\n",
    "    conn = ibis.connect('duckdb://:memory:')\n",
    "\n",
    "    dpath = '{os.path.join(os.path.abspath('.'), FARM_DATA_DIR)}'\n",
    "    for file in os.listdir(dpath):\n",
    "        if '.parquet' in file:\n",
    "            conn.register(os.path.join(dpath, file), file.split('/')[-1].replace('.parquet', ''))\n",
    "    return conn\n",
    "\"\"\"\n",
    "\n",
    "beaccess_kwargs['pandas'] = f\"\"\"\n",
    "def pandas_conn():\n",
    "    dfs = dict()\n",
    "    dpath = '{os.path.join(os.path.abspath('.'), FARM_DATA_DIR)}'\n",
    "    \n",
    "    for file in os.listdir(dpath):\n",
    "        if '.parquet' in file:\n",
    "            dfs[file.replace('.parquet', '')] = pd.read_parquet(os.path.join(dpath, file))\n",
    "\n",
    "    conn = ibis.pandas.connect(dfs)\n",
    "    return conn\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ee225f-cd6f-4d9b-ae9b-828154abbc76",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### \"Postgres\"\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️:</b> Alters Postgres Instance public Schema\n",
    "\n",
    "    This writes tables into a postgres `public` schema. If the table exists, that table will be overwritten.\n",
    "</div>\n",
    "\n",
    "If you are using the Postgres backend, then you will be using the `public` schema to store your data.\n",
    "\n",
    "You should have a [.pgpass file](https://www.postgresql.org/docs/9.3/libpq-pgpass.html) in your home directory (`~/`).\n",
    "This will make connecting simple since you won't need to type your password every time you connect.\n",
    "\n",
    "Connect to your database using a connection string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06ea2b6b-0e36-4f90-8b70-f6d1696a0647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ibis\n",
    "\n",
    "cstring = 'postgres://<username>@<host>:<port>/<database>'\n",
    "\n",
    "conn = ibis.connect(cstring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd23dae-5c17-4f43-837e-aa22fe8bd17f",
   "metadata": {},
   "source": [
    "#### Writing Using the Above Connection\n",
    "After you've chosen your connection method and it has create table permissions, you will be able to connect and write your data.\n",
    "You will use `pandas.DataFrame.to_sql` to write this data to your postgres instance's `public` schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e87dc00a-0fa7-4283-8021-25c8c6d822bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Array type function\n",
    "arr_f = ibis.backends.postgres.sa.types.ARRAY\n",
    "\n",
    "# Decimal type\n",
    "dec_type = ibis.backends.postgres.sa.types.DECIMAL()\n",
    "\n",
    "# Integer type\n",
    "int_type = ibis.backends.postgres.sa.types.INT()\n",
    "\n",
    "# Text type\n",
    "str_type = ibis.backends.postgres.sa.types.Text()\n",
    "\n",
    "# Need to make sure our data types are mapped correctly.\n",
    "# Define schemas explicitly.\n",
    "schemas = {\n",
    "    'farmers': {\n",
    "        'farmer_id': int_type\n",
    "        ,'farmer_name': str_type\n",
    "    }\n",
    "    ,'farms': {\n",
    "        'farm_id': int_type\n",
    "        ,'farm_name': str_type\n",
    "        ,'farm_address': str_type\n",
    "        ,'farm_origin_x': int_type\n",
    "        ,'farm_origin_y': int_type\n",
    "    }\n",
    "    ,'tracts': {\n",
    "        'tract_id': int_type\n",
    "        ,'farm_id': int_type\n",
    "    }\n",
    "    ,'fields': {\n",
    "        'field_id': int_type\n",
    "        ,'field_tract_id': int_type\n",
    "        ,'field_vertices': arr_f(int_type)\n",
    "    }\n",
    "    ,'dates': {\n",
    "        'date_id': int_type\n",
    "        ,'date_year': int_type\n",
    "        ,'date_month': int_type\n",
    "        ,'date_day': int_type\n",
    "    }\n",
    "    ,'crops': {\n",
    "        'crop_id': int_type\n",
    "        ,'crop_name': str_type\n",
    "        ,'crop_unit': str_type\n",
    "    }\n",
    "    ,'farmer_groups': {\n",
    "        'farmer_group_id': int_type\n",
    "        ,'farmer_group_members': str_type\n",
    "    }\n",
    "    ,'harvest': {\n",
    "        'harvest_id': int_type\n",
    "        ,'harvest_field_id': int_type\n",
    "        ,'harvest_farmer_group_id': int_type\n",
    "        ,'harvest_crop_id': int_type\n",
    "        ,'harvest_date_id': int_type\n",
    "        ,'harvest_value': dec_type\n",
    "    }\n",
    "}\n",
    "\n",
    "for key in data:\n",
    "    df = pd.DataFrame(data[key][1:], columns=data[key][0])\n",
    "    df.to_sql(\n",
    "        name=key\n",
    "        ,con=conn.con.connect()\n",
    "        ,if_exists='replace'\n",
    "        ,index=False\n",
    "        ,dtype=schemas[key]\n",
    "    )\n",
    "\n",
    "beaccess_kwargs['postgres'] = f\"\"\"\n",
    "def postgres_conn():\n",
    "    return ibis.connect('{cstring}')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402e317f-021d-4f66-b9dd-744bb65c9743",
   "metadata": {},
   "source": [
    "## 0.1.4 Write to `beaccess.py`\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️:</b> Alters Current Directory\n",
    "\n",
    "    The next block creates a new .py file, beaccess.py, in the current directory and writes to it.\n",
    "    If the file exists, then that file will be overwritten.\n",
    "</div>\n",
    "\n",
    "Each block above created a series of arguments that allow this section to create and modify `beaccess.py`.\n",
    "By running the code below, you will create a function that allows you to establish an ibis connection\n",
    "to the data you've created.\n",
    "\n",
    "The next chapter will explain how to establish a connection, but every other chapter will use this connection.\n",
    "Be sure to, at the very least, create a module `beaccess.py` with a function `connect` that returns an ibis\n",
    "backend connection to your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "825234e0-8739-40dc-96f9-6a5cc82002e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_backend = 'duckdb' if 'duckdb' in beaccess_kwargs.keys() else beaccess_kwargs.keys()[0]\n",
    "\n",
    "fns = '\\n'.join(beaccess_kwargs.values())\n",
    "\n",
    "fdict = (\n",
    "    'dict(\\n        '\n",
    "    + '\\n        ,'.join(\n",
    "        '='.join([k, v.split('\\n')[1].replace('def ', '').replace(':', '')])\n",
    "        for k, v in beaccess_kwargs.items()\n",
    "    )\n",
    "    + '\\n    )'\n",
    ")\n",
    "\n",
    "script_string = f\"\"\"import os\n",
    "import ibis\n",
    "import pandas as pd\n",
    "\n",
    "{fns}\n",
    "\n",
    "def connect(backend='{default_backend}'):\n",
    "    return {fdict}[backend]\n",
    "\"\"\"\n",
    "\n",
    "with open('./beaccess.py', 'w') as f:\n",
    "    f.seek(0)\n",
    "    f.truncate()\n",
    "\n",
    "    f.write(script_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fcb6906-fbdb-4f4d-add7-2f089adf0ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duckdb ['crops', 'dates', 'farmer_groups', 'farmers', 'farms', 'fields', 'harvest', 'tracts']\n",
      "pandas ['tracts', 'harvest', 'farms', 'farmers', 'crops', 'fields', 'farmer_groups', 'dates']\n",
      "postgres ['array_test', 'array_data', 'farmers', 'farms', 'tracts', 'fields', 'dates', 'crops', 'farmer_groups', 'harvest']\n"
     ]
    }
   ],
   "source": [
    "import beaccess as bea\n",
    "\n",
    "for key in beaccess_kwargs:\n",
    "    conn = bea.connect(key)\n",
    "    print(key, conn.list_tables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a8053e-7f90-49ed-8a0e-9dbcfce88467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
